## Regression
- Stock Market Forecast
- Self-driving Car
- Recommendation
- Example
  - Model
    - Function: y=b+w*x (linear function)
    - Goodness of Function: 
    - Loss Function:
$$ 
L(w,b)=\sum_{n=1}^{10}(\hat{y}^n-(b+w*x_{cp}^n))^2
$$
    - Best Function:
$$
\begin{align}
w^*,b^*&= arg \underset{w,b}{min} L(w,b)\\
       &= arg \underset{w,b}{min}\sum_{n=1}^{10}(\hat{y}^n-(b+w\cdot x_{cp}^n))^2
\end {align}
$$
    - Gradient Descent
$$ w^*=arg \underset{w}{min}L(w)
$$
      - Consider loss function L(w) with one parameter w:
        1. Pick an initial value $w^0$
        2. Compute $\frac{dL}{dw}|_w=w^0$
        3. Compute $\frac{dL}{dw}|_w=w^1$
$w^1\leftarrow w^0-\eta\frac{dL}{dw}|_{w=w^0}$
$w^2\leftarrow w^1-\eta\frac{dL}{dw}|_{w=w^1}$
$\eta$: learning rate
      - How about two parameters?   $w^*,b^*=arg \underset{w,b}{min}L(w,b)$
        1. Pick an initial value $w^0,b^0$
        2. Compute $\frac{\partial L}{\partial w}|_{w=w^0,b=b^0},\frac{\partial L}{\partial b}|_{w=w^0,b=b^0}$
        3. Compute $\frac{\partial L}{\partial w}|_{w=w^1,b=b^1},\frac{\partial L}{\partial b}|_{w=w^1,b=b^1}$
$w^i\leftarrow w^{i-1}-\eta \frac{\partial L}{\partial w}|_{w=w^{i-2},b=b^{i-2}}$
$b^i\leftarrow b^{i-1}-\eta \frac{\partial L}{\partial b}|_{w=w^{i-2},b=b^{i-2}}$
$\nabla L=\begin {bmatrix}\frac {\partial L}{\partial w}\\ \frac{\partial L}{\partial b}\\ \end{bmatrix}_ {gradient}$
      - Formulation of $\partial L/\partial w$ and $\partial L/\partial b$
$L(w,b)=\sum_{n=1}^{10}(\hat{y}^n-(b+w\cdot x_{cp}^n))^2$
$\frac{\partial L}{\partial w}=? \sum_{n=1}^{10}2(\hat{y}^n-(b+w\cdot x_{cp}^n))(-x_{cp}^n)$
$\frac{\partial L}{\partial b}=?\sum_{n=1}^{10}2(\hat{y}^n-(b-w\cdot x_{cp}^n))$

      - Model Selection
        1. $y=b+w\cdot x_{cp}$
        2. $y=b+w_{1}\cdot x_{cp}+w_{2}\cdot (x_{cp})^2$
        3. $y=b+w_{1}\cdot x_{cp}+w_{2}\cdot (x_{cp})^2+w_{3}\cdot(x_{cp})^3$
        A More complex model yields lower error on **training data**.
        A more complex model does not always lead to better performance on **testing data**.
        This is ***overfitting***.